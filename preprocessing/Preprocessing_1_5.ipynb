{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "\n",
    "### Outline ###\n",
    "#\n",
    "# 1) Concatenate PRESCRIPTIONS (mimic med) drug name, amount, and units of measurement into a single variable (we'll\n",
    "#     replace the previous code_name with this to maintain consistency across scripts)\n",
    "#         - Input: one .pkl file created by Preprocessed_1.ipynb (mimic_med_PRESCRIPTIONS_init.pkl) \n",
    "#         - Output: one .pkl file to output_dir (mimic_med_PRESCRIPTIONS_init.pkl)\n",
    "#\n",
    "# 2) Merge the INPUTEVENTS_CV and INPUTEVENTS_MV information along the common variables they share from \n",
    "#     running through Preprocessed_1.ipynb\n",
    "#         - Input: two .pkl files created by Preprocessed_1.ipynb (mimic_inf_INPUTEVENTS_CV_init.pkl; mimic_inf_INPUTEVENTS_MV_init.pkl)\n",
    "#         - Output: a DataFrame named < concat >, stored in memory for (3)\n",
    "#\n",
    "# 3) Process INPUTEVENTS from MIMIC to approximate the eICU infusion_drug file's code_name. That is, concatenate\n",
    "#     drug name and dosage units of measurement into one variable\n",
    "#         - Input: the < concat > DataFrame generated by (2)\n",
    "#         - Output: a .pkl file to output_dir\n",
    "#\n",
    "\n",
    "input_dir = '../../../output/PrePr1_output_Wes/'\n",
    "output_dir = '../../../output/PrePr1-5_output_Wes/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning mimic med code_name/amount/units concatenation...\n",
      "Inputdir is:  ../../../output/PrePr1_output_Wes/   ;   Output dir is:  ../../../output/PrePr1-5_output_Wes/\n",
      "Output file: < mimic_med_PRESCRIPTIONS_init.pkl > to  ../../../output/PrePr1-5_output_Wes/\n",
      "Finished mimic med code_name/amount/units concatenation.\n"
     ]
    }
   ],
   "source": [
    "### 1: Concat mimic med\n",
    "print('Beginning mimic med code_name/amount/units concatenation...')\n",
    "print('Inputdir is: ', input_dir, '  ;  ', 'Output dir is: ', output_dir) \n",
    "\n",
    "presc = pd.read_pickle(os.path.join(input_dir, 'mimic_med_PRESCRIPTIONS_init.pkl'))\n",
    "\n",
    "'''\n",
    "Recall: \n",
    "        'PRESCRIPTIONS':{'HADM_ID':'ID','STARTDATE':'start_time', 'ENDDATE':'end_time', \n",
    "                         'DRUG':'code_name','DOSE_VAL_RX':'value','DOSE_UNIT_RX':'value_uom',\n",
    "                         'ROUTE':'route', 'DRUG_TYPE':'drug_type','FORM_VAL_DISP':'val_disp' ,\n",
    "                         'FORM_UNIT_DISP':'unit_disp'}\n",
    "                         \n",
    "--> We care about: code_name, value, value_uom\n",
    "'''\n",
    "\n",
    "presc = presc.rename(columns={'code_name':'code_name_old'})\n",
    "\n",
    "presc['code_name'] = pd.Series([[i+' '+str(j)+' '+k+' '+l for i,j,k,l in zip(presc['code_name_old'].iloc[z], \\\n",
    "                                                                     presc['value'].iloc[z], \\\n",
    "                                                                     presc['value_uom'].iloc[z], \\\n",
    "                                                                     presc['route'].iloc[z])] \\\n",
    "                               for z in range(len(presc.index))])\n",
    "\n",
    "presc = presc.drop('code_name_old', axis=1)\n",
    "presc.to_pickle(os.path.join(output_dir, 'mimic_med_PRESCRIPTIONS_init.pkl'))\n",
    "\n",
    "print('Output file: < mimic_med_PRESCRIPTIONS_init.pkl > to ', output_dir)\n",
    "print('Finished mimic med code_name/amount/units concatenation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning INPUTEVENTS CV-MV merge...\n",
      "Reading files...\n",
      "Files read.\n",
      "Files concatenated.\n",
      "Not all columns in new file shared between original files.\n",
      " Cols not in CV:  ['start_time', 'end_time', 'patient_weight'] \n",
      " Cols not in MV:  []\n",
      "Finished INPUTEVENTS CV-MV concatenation.\n"
     ]
    }
   ],
   "source": [
    "### 2: Merge INPUTEVENTS _CV and _MV\n",
    "\n",
    "print('Beginning INPUTEVENTS CV-MV merge...')\n",
    "\n",
    "print('Reading files...') # these are big files, so we'll flag this process (could take a few seconds locally)\n",
    "ie_cv = pd.read_pickle(os.path.join(input_dir, 'mimic_inf_INPUTEVENTS_CV_init.pkl'))\n",
    "ie_mv = pd.read_pickle(os.path.join(input_dir, 'mimic_inf_INPUTEVENTS_MV_init.pkl'))\n",
    "print('Files read.')\n",
    "\n",
    "concat = pd.concat([ie_cv, ie_mv])\n",
    "print('Files concatenated.')\n",
    "\n",
    "# General practice for concatenating: check columns\n",
    "not_intersection_mv = [col for col in concat.columns if col not in ie_mv.columns]\n",
    "not_intersection_cv = [col for col in concat.columns if col not in ie_cv.columns]\n",
    "\n",
    "if not_intersection_mv != [] or not_intersection_cv != []:\n",
    "    print('Not all columns in new file shared between original files.')\n",
    "    print(' Cols not in CV: ', not_intersection_cv, '\\n Cols not in MV: ', not_intersection_mv)\n",
    "\n",
    "# Uncomment if part (3) is not being run    \n",
    "# concat.to_pickle(os.path.join(output_dir, 'mimic_inf_INPUTEVENTS_merged_init.pkl'))\n",
    "# print('Output file: < mimic_inf_INPUTEVENTS_merged_init.pkl > to ', output_dir)\n",
    "\n",
    "print('Finished INPUTEVENTS CV-MV concatenation.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning INPUTEVENTS_merged code_name processing...\n",
      "New code_name generated after 5.703 seconds.\n",
      "Writing file...\n",
      "Output file < mimic_inf_INPUTEVENTS_merged_init.pkl > to ../../../output/PrePr1-5_output_Wes/ after 116.386 seconds.\n",
      "Finished INPUTEVENTS_merged code_name processing.\n"
     ]
    }
   ],
   "source": [
    "### 3: Process INPUTEVENTS from MIMIC\n",
    "\n",
    "start = time.time()\n",
    "print('Beginning INPUTEVENTS_merged code_name processing...')\n",
    "\n",
    "concat['code_name_new'] = pd.Series([[(str(i)+' ' \\\n",
    "                                           +('('+str(j)+')').replace('(null)','')+' '\\\n",
    "                                           +('('+str(k)+')').replace('(null)','')).replace('  ',' ').strip() \\\n",
    "                              for i,j,k in zip(concat['code_name'].iloc[z], \\\n",
    "                                              concat['value_uom'].iloc[z], \\\n",
    "                                              concat['rateuom'].iloc[z])] \\\n",
    "                               for z in range(len(concat.index))])\n",
    "concat = concat.drop('code_name', axis=1)\n",
    "concat = concat.rename(columns={'code_name_new':'code_name'})\n",
    "checkpoint1 = time.time()\n",
    "print('New code_name generated after', round((checkpoint1-start),3), 'seconds.')\n",
    "\n",
    "\n",
    "print('Writing file...') # seems that the line below takes quite a bit of time! (though, it is a 500MB file)\n",
    "concat.to_pickle(os.path.join(output_dir, 'mimic_inf_INPUTEVENTS_merged_init.pkl'))\n",
    "\n",
    "checkpoint2 = time.time()\n",
    "print('Output file < mimic_inf_INPUTEVENTS_merged_init.pkl > to', output_dir, \\\n",
    "      'after', round((checkpoint2-start),3), 'seconds.')\n",
    "\n",
    "print('Finished INPUTEVENTS_merged code_name processing.')\n",
    "\n",
    "#  An alternative idea would have been to process the eICU data to extract the measurement unit information\n",
    "#  and put it in a separate column as another feature. However, while this is easy for the first 100-200 rows, \n",
    "#  (as all measurements are contained in parentheses and can be regex-ed out), soon other drug names include\n",
    "#  the same string pattern for non-measurements, making automatic identification of units quite diffifult. \n",
    "#  Naive code below:\n",
    "#\n",
    "# eicu_inf = pd.read_pickle(os.path.join(input_dir, 'eicu_inf_infusionDrug_init.pkl'))\n",
    "# test_eicu = eicu_inf.copy()\n",
    "# test_eicu['code_name_unit'] = pd.Series([[i[i.find('(')+1:i.find(')')] for i in test_eicu['code_name'][k]] \\\n",
    "#                                   for k in range(len(test_eicu.index))])\n",
    "# test_eicu['mod_code_name'] = pd.Series([[re.sub(r'\\ \\([^)]*\\)', '', i) for i in test_eicu['code_name'][k]] \\\n",
    "#                                   for k in range(len(test_eicu.index))])\n",
    "# units = [i for k in range(len(test_eicu.index)) for i in test_eicu.code_name_unit[k]]\n",
    "# print(pd.Series(units).unique())\n",
    "# test_eicu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
