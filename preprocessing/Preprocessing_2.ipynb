{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import notebook\n",
    "from collections import Counter\n",
    "\n",
    "input_1_dir = '../../../output/PrePr1_output_Wes/' # This is a bit messy -- let's clean this up later. \n",
    "input_1_5_dir = '../../../output/PrePr1-5_output_Wes/' # We don't really need a separate directory for each step\n",
    "output_dir = '../../../output/PrePr2_output_Wes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = ['mimic', 'eicu']\n",
    "items = ['lab','med','inf']\n",
    "window_time = 12\n",
    "UNK = False\n",
    "max_len = 150\n",
    "min_freq = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_files = {'lab':'LABEVENTS', 'med':'PRESCRIPTIONS', 'inf':'INPUTEVENTS_merged'}\n",
    "\n",
    "eicu_files = {'dx':'diagnosis', 'lab':'lab', 'med':'medication', \n",
    "                   'trt':'treatment', 'inf':'infusionDrug'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess(): \n",
    "    def __init__(self, cohort, src:str, item:str, window, UNK, max_len, min_freq):\n",
    "        self.cohort = cohort\n",
    "        self.src = src\n",
    "        self.UNK = UNK\n",
    "        self.window = window\n",
    "        self.max_len = max_len\n",
    "        self.min_freq = min_freq\n",
    "        #이부분 수정 필요\n",
    "        self.offset = 'order_offset'\n",
    "        self.item = item\n",
    "            \n",
    "       \n",
    "        if self.window=='Total':\n",
    "            self.name_window = '{}_name'.format(self.item)\n",
    "            self.offset_window = self.offset\n",
    "            self.offset_order = 'offset_order'\n",
    "        else:\n",
    "            self.name_window = '{}_name_{}hr'.format(self.item, str(self.window))\n",
    "            self.offset_window = '{}_{}hr'.format(self.offset, str(self.window))\n",
    "            self.offset_order = '{}_offset_order_{}hr'.format(self.item, str(self.window))\n",
    "    \n",
    "    def timeoffset_window(self): \n",
    "        #(input: timeoffset -output:timeoffset_window):\n",
    "        if self.window == 'Total':\n",
    "                pass\n",
    "        else:\n",
    "            offset_window_lst = []\n",
    "            code_name_window_lst = []\n",
    "            for idx, offset_lst in enumerate(self.cohort[self.offset]): # time since order, e.g. [182, 182, 403, 403, 403]\n",
    "                len_offset_window = len([offset for offset in offset_lst if offset < self.window*60]) # how many < max_time \n",
    "                code_name_lst = self.cohort.code_name.iloc[idx] # which medically relevant thing [e.g. Tylenol 500mg, Epinephrine X mL]\n",
    "                offset_window = offset_lst[:len_offset_window] # truncate both at length of offset window\n",
    "                code_name_window = code_name_lst[:len_offset_window]\n",
    "                offset_window_lst.append(offset_window) # our new truncated window\n",
    "                code_name_window_lst.append(code_name_window) # our new truncated codes\n",
    "            self.cohort[self.name_window] = pd.Series(code_name_window_lst) # add as new column at end\n",
    "            self.cohort[self.offset_window] = pd.Series(offset_window_lst)\n",
    "        return self.cohort\n",
    "    \n",
    "    def timeoffset_timeorder(self, cohort): \n",
    "        #(input- timeoffset - timeorder)\n",
    "        offset_order_lst = []\n",
    "        for idx, offset in enumerate(cohort[self.offset_window]):\n",
    "            offset_set = list(set(offset)) # create a set from the interable e.g. {122, 232, 444}\n",
    "            offset_set.sort() \n",
    "            order_value = np.arange(1, len(offset_set)+1)\n",
    "            dict_offset = dict(zip(offset_set, order_value)) # create dictionary of \"order\" of events\n",
    "            offset_order = list(pd.Series(offset).map(dict_offset)) \n",
    "            offset_order_lst.append(offset_order)\n",
    "        cohort[self.offset_order] = pd.Series(offset_order_lst) # offset order is new col indicating ordinality\n",
    "        return cohort\n",
    "    \n",
    "    def code_windowed(self, cohort, max_len, min_len):\n",
    "        name_lst= []\n",
    "        offset_lst = []\n",
    "        offset_order_lst = []\n",
    "        zero_len_idx=[]\n",
    "        for idx, names in enumerate(self.cohort[self.name_window]): # our truncated code_name column\n",
    "            len_name_window=len(names) # how many of these codes in our iteratred row?\n",
    "            if len_name_window > max_len:\n",
    "                 len_name_window = max_len\n",
    "            if len_name_window < min_len:\n",
    "                zero_len_idx.append(idx) \n",
    "            name = names[:len_name_window] # truncate to the max number of codes we're allowing\n",
    "            offset = cohort[self.offset_window].iloc[idx][:len_name_window] # ditto for the [132, 132, 144, etc.]\n",
    "            offset_order = cohort[self.offset_order].iloc[idx][:len_name_window] # ditto to the order of events (1,2,3..)\n",
    "            name_lst.append(name) # build series\n",
    "            offset_lst.append(offset)\n",
    "            offset_order_lst.append(offset_order)    \n",
    "        cohort[self.name_window] = pd.Series(name_lst) # replace columns from 1st fxn as necessary\n",
    "        cohort[self.offset_window] = pd.Series(offset_lst)\n",
    "        cohort[self.offset_order] = pd.Series(offset_order_lst)\n",
    "        \n",
    "        self.cohort = self.cohort.drop(self.cohort.index[[zero_len_idx]]).reset_index(drop=True) # drop if not enough time obs\n",
    "        return self.cohort\n",
    "    \n",
    "                \n",
    "    def make_vocab(self, cohort, min_freq=5, PAD_idx=0, UNK_idx=1, MASK_idx=2, SEP_idx=3): \n",
    "        #(Input codes output vocab with PAD 0 UNK 1 MASK 2 SEP 3)\n",
    "        #2 options : delete UNK (min_freq) : False or treat min_freq as  UNK : True\n",
    "       \n",
    "        flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "        word_freq = dict(Counter(flatten(cohort[self.name_window])))\n",
    "        \n",
    "        if self.UNK == True:\n",
    "            word2idx = {'<PAD>': PAD_idx, '<UNK>': UNK_idx, '<MASK>':MASK_idx, '<SEP>':SEP_idx} \n",
    "            \n",
    "        elif self.UNK == False:\n",
    "            word2idx = {'<PAD>': PAD_idx, '<MASK>':MASK_idx, '<SEP>':SEP_idx}\n",
    "        \n",
    "\n",
    "        min_freq_id=[]\n",
    "        for word_item in word_freq.items():\n",
    "            if word_item[0] not in word2idx:\n",
    "                if word_item[1] < min_freq:\n",
    "                    min_freq_id.append(word_item[0])\n",
    "                    if self.UNK== True:\n",
    "                        word2idx[word_item[0]]=1 #UNK 처리 \n",
    "                else:\n",
    "                    word2idx[word_item[0]] = max(word2idx.values())+1\n",
    "                    \n",
    "        return word2idx, min_freq_id\n",
    "    \n",
    "    def code_to_index(self, cohort, word2idx, min_freq_id):\n",
    "        #deleting min_freq word\n",
    "        if self.UNK == False:\n",
    "            dict_del={}\n",
    "            for idx, name_lst in enumerate(cohort[self.name_window]):\n",
    "                del_index=[i for i in range(len(name_lst)) if name_lst[i] in min_freq_id]              \n",
    "                if len(del_index)>0:\n",
    "                    dict_del[idx]=del_index \n",
    "            for idx, order in (dict_del.items()):\n",
    "                item_deleted = [i for j, i in enumerate(cohort[self.name_window][idx]) if j not in order]\n",
    "                offset_deleted = [i for j, i in enumerate(cohort[self.offset_window][idx]) if j not in order]\n",
    "                offset_order_deleted= [i for j, i in enumerate(cohort[self.offset_order][idx]) if j not in order]\n",
    "             #value_deleted\n",
    "                #measure_deleted\n",
    "                cohort[self.name_window].iloc[idx] = item_deleted\n",
    "                cohort[self.offset_window].iloc[idx] = offset_deleted\n",
    "                cohort[self.offset_order].iloc[idx] = offset_order_deleted\n",
    "        #mapping\n",
    "        item_id=[]    \n",
    "        for name_lst in cohort[self.name_window]:\n",
    "            item_id_lst=list(pd.Series(name_lst).map(word2idx))\n",
    "            item_id.append(item_id_lst)\n",
    "        item_id = pd.Series(item_id)\n",
    "        cohort['{}_id_{}hr'.format(self.item, str(self.window))]=item_id\n",
    "        \n",
    "        return cohort\n",
    "     \n",
    "    def arguments(self):\n",
    "        return  [self.src, self.window, self.item]\n",
    "    \n",
    "    def __call__(self):\n",
    "        cohort = self.timeoffset_window()\n",
    "        cohort = self.timeoffset_timeorder(cohort)\n",
    "        cohort = self.code_windowed(cohort, self.max_len, self.min_freq)\n",
    "        word2idx, min_freq_id = self.make_vocab(cohort, min_freq=self.min_freq, PAD_idx=0, UNK_idx=1, MASK_idx=2, SEP_idx=3)\n",
    "        cohort = self.code_to_index(cohort, word2idx, min_freq_id)\n",
    "        return cohort, word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cohort file mimic_lab_LABEVENTS_init.pkl from ../../../output/PrePr1_output_Wes/ ...\n",
      "File read.\n",
      "Preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-0e3491782891>:49: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  offset_order = list(pd.Series(offset).map(dict_offset))\n",
      "/Users/Wesley/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3941: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n",
      "/Users/Wesley/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed.\n",
      "Writing mimic_12_lab_150.pkl to ../../../output/PrePr2_output_Wes/\n",
      "Generated vocabulary of length 362 \n",
      "\n",
      "Reading cohort file mimic_med_PRESCRIPTIONS_init.pkl from ../../../output/PrePr1-5_output_Wes/ ...\n",
      "File read.\n",
      "Preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-0e3491782891>:49: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  offset_order = list(pd.Series(offset).map(dict_offset))\n",
      "/Users/Wesley/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3941: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n",
      "/Users/Wesley/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "<ipython-input-4-0e3491782891>:125: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  item_id_lst=list(pd.Series(name_lst).map(word2idx))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed.\n",
      "Writing mimic_12_med_150.pkl to ../../../output/PrePr2_output_Wes/\n",
      "Generated vocabulary of length 1933 \n",
      "\n",
      "Reading cohort file mimic_inf_INPUTEVENTS_merged_init.pkl from ../../../output/PrePr1-5_output_Wes/ ...\n",
      "File read.\n",
      "Preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-0e3491782891>:49: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  offset_order = list(pd.Series(offset).map(dict_offset))\n",
      "/Users/Wesley/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3941: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n",
      "/Users/Wesley/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed.\n",
      "Writing mimic_12_inf_150.pkl to ../../../output/PrePr2_output_Wes/\n",
      "Generated vocabulary of length 350 \n",
      "\n",
      "Reading cohort file eicu_lab_lab_init.pkl from ../../../output/PrePr1_output_Wes/ ...\n",
      "File read.\n",
      "Preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-0e3491782891>:49: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  offset_order = list(pd.Series(offset).map(dict_offset))\n",
      "/Users/Wesley/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3941: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n",
      "/Users/Wesley/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed.\n",
      "Writing eicu_12_lab_150.pkl to ../../../output/PrePr2_output_Wes/\n",
      "Generated vocabulary of length 136 \n",
      "\n",
      "Reading cohort file eicu_med_medication_init.pkl from ../../../output/PrePr1_output_Wes/ ...\n",
      "File read.\n",
      "Preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-0e3491782891>:49: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  offset_order = list(pd.Series(offset).map(dict_offset))\n",
      "/Users/Wesley/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3941: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n",
      "/Users/Wesley/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed.\n",
      "Writing eicu_12_med_150.pkl to ../../../output/PrePr2_output_Wes/\n",
      "Generated vocabulary of length 962 \n",
      "\n",
      "Reading cohort file eicu_inf_infusionDrug_init.pkl from ../../../output/PrePr1_output_Wes/ ...\n",
      "File read.\n",
      "Preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-0e3491782891>:49: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  offset_order = list(pd.Series(offset).map(dict_offset))\n",
      "/Users/Wesley/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3941: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n",
      "/Users/Wesley/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "<ipython-input-4-0e3491782891>:125: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  item_id_lst=list(pd.Series(name_lst).map(word2idx))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed.\n",
      "Writing eicu_12_inf_150.pkl to ../../../output/PrePr2_output_Wes/\n",
      "Generated vocabulary of length 565 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for src in sources: \n",
    "    for item in items: \n",
    "        if src=='mimic':\n",
    "            file = mimic_files[item]\n",
    "        if src=='eicu':\n",
    "            file = eicu_files[item]\n",
    "        \n",
    "        filename = '{}_{}_{}_init.pkl'.format(src,item,file)\n",
    "        \n",
    "        if src=='mimic' and (item=='inf' or item=='med'):\n",
    "            input_dir = input_1_5_dir\n",
    "        else: \n",
    "            input_dir = input_1_dir\n",
    "        \n",
    "        print('Reading cohort file', filename, 'from', input_dir, '...')\n",
    "        cohort = pd.read_pickle(os.path.join(input_dir,filename))\n",
    "        print('File read.')\n",
    "        \n",
    "        print('Preprocessing...') \n",
    "        df = Preprocess(cohort, src, item, window_time, UNK, max_len, min_freq)\n",
    "        cohort, vocab = df()\n",
    "        print('Preprocessing completed.')\n",
    "        \n",
    "        print('Writing', '{}_{}_{}_{}.pkl'.format(src, window_time, item, max_len), 'to', output_dir)\n",
    "        cohort.to_pickle(os.path.join(output_dir,'{}_{}_{}_{}.pkl'.format(src, window_time, item, max_len)))\n",
    "        \n",
    "        # As an extra check: \n",
    "        print('Generated vocabulary of length', len(vocab), '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
